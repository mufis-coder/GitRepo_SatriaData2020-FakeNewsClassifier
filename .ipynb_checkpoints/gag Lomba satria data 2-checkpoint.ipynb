{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOdBfsgodiLw"
   },
   "source": [
    "# **Import Libarary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_915wqwYWvU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJRWgEwIdn-3"
   },
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27k0VIpbYWvl",
    "outputId": "8246c86f-2b42-42ec-fe9b-d9ca163534ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>nama file gambar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-17 00:00:00</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "      <td>71.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17 00:00:00</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "      <td>461.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-13 00:00:00</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "      <td>495.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-08 00:00:00</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "      <td>550.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-24 00:00:00</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "      <td>681.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-17 00:00:00</td>\n",
       "      <td>event promo smartphone JNE 2020 spesial di bul...</td>\n",
       "      <td>selamat siang teman teman fb ku semuanyaü§©,cuma...</td>\n",
       "      <td>736.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1161</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-05 00:00:00</td>\n",
       "      <td>MEREKA SUDAH MEMPERSIAPKAN DIRI DENGAN BAIK UN...</td>\n",
       "      <td>LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...</td>\n",
       "      <td>1161.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1597</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:00:00</td>\n",
       "      <td>Foto Presiden Italia menangis karena tak cukup...</td>\n",
       "      <td>Italia punya fasilitas perawatan kesehatan ter...</td>\n",
       "      <td>1597.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2098</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-09 00:00:00</td>\n",
       "      <td>Kapolres Timor Tengah Utara , Nusa Tenggara Ti...</td>\n",
       "      <td>Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...</td>\n",
       "      <td>2098.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2226</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-24 00:00:00</td>\n",
       "      <td>Video Polisi china telah menganiaya wanita uig...</td>\n",
       "      <td>Polisi china telah menganiaya wanita uighur le...</td>\n",
       "      <td>2226.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  label              tanggal  \\\n",
       "0    71      1  2020-08-17 00:00:00   \n",
       "1   461      1  2020-07-17 00:00:00   \n",
       "2   495      1  2020-07-13 00:00:00   \n",
       "3   550      1  2020-07-08 00:00:00   \n",
       "4   681      1  2020-06-24 00:00:00   \n",
       "5   736      1  2020-06-17 00:00:00   \n",
       "6  1161      1  2020-05-05 00:00:00   \n",
       "7  1597      1  2020-03-24 00:00:00   \n",
       "8  2098      1  2020-01-09 00:00:00   \n",
       "9  2226      1  2019-12-24 00:00:00   \n",
       "\n",
       "                                               judul  \\\n",
       "0  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "5  event promo smartphone JNE 2020 spesial di bul...   \n",
       "6  MEREKA SUDAH MEMPERSIAPKAN DIRI DENGAN BAIK UN...   \n",
       "7  Foto Presiden Italia menangis karena tak cukup...   \n",
       "8  Kapolres Timor Tengah Utara , Nusa Tenggara Ti...   \n",
       "9  Video Polisi china telah menganiaya wanita uig...   \n",
       "\n",
       "                                              narasi nama file gambar  \n",
       "0  A caller to a radio talk show recently shared ...           71.jpg  \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...          461.png  \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...          495.png  \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...          550.png  \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .          681.jpg  \n",
       "5  selamat siang teman teman fb ku semuanyaü§©,cuma...          736.png  \n",
       "6  LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...         1161.png  \n",
       "7  Italia punya fasilitas perawatan kesehatan ter...         1597.png  \n",
       "8  Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...         2098.jpg  \n",
       "9  Polisi china telah menganiaya wanita uighur le...         2226.png  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('D:\\zzKoding\\Data Sains - Machine Learning - AI\\Lomba\\Satria Data 2020\\Data\\Salinan Data Latih BDC.xlsx')\n",
    "df_judul = df['judul']\n",
    "df_narasi = df['narasi']\n",
    "df_label = df['label']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mg4fGqErYWvx",
    "outputId": "7b27eda0-5720-4c3f-a564-217074ab1d11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>event promo smartphone JNE 2020 spesial di bul...</td>\n",
       "      <td>selamat siang teman teman fb ku semuanyaü§©,cuma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1161</td>\n",
       "      <td>1</td>\n",
       "      <td>MEREKA SUDAH MEMPERSIAPKAN DIRI DENGAN BAIK UN...</td>\n",
       "      <td>LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1597</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Presiden Italia menangis karena tak cukup...</td>\n",
       "      <td>Italia punya fasilitas perawatan kesehatan ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2098</td>\n",
       "      <td>1</td>\n",
       "      <td>Kapolres Timor Tengah Utara , Nusa Tenggara Ti...</td>\n",
       "      <td>Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2226</td>\n",
       "      <td>1</td>\n",
       "      <td>Video Polisi china telah menganiaya wanita uig...</td>\n",
       "      <td>Polisi china telah menganiaya wanita uighur le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  label                                              judul  \\\n",
       "0    71      1  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1   461      1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2   495      1  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3   550      1  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4   681      1       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "5   736      1  event promo smartphone JNE 2020 spesial di bul...   \n",
       "6  1161      1  MEREKA SUDAH MEMPERSIAPKAN DIRI DENGAN BAIK UN...   \n",
       "7  1597      1  Foto Presiden Italia menangis karena tak cukup...   \n",
       "8  2098      1  Kapolres Timor Tengah Utara , Nusa Tenggara Ti...   \n",
       "9  2226      1  Video Polisi china telah menganiaya wanita uig...   \n",
       "\n",
       "                                              narasi  \n",
       "0  A caller to a radio talk show recently shared ...  \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...  \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...  \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...  \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .  \n",
       "5  selamat siang teman teman fb ku semuanyaü§©,cuma...  \n",
       "6  LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...  \n",
       "7  Italia punya fasilitas perawatan kesehatan ter...  \n",
       "8  Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...  \n",
       "9  Polisi china telah menganiaya wanita uighur le...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df = df.drop(['tanggal', 'nama file gambar'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Shyw-LX7YWv5",
    "outputId": "02babc96-285d-4e35-8111-156bc91de7c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4231 entries, 0 to 4230\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      4231 non-null   int64 \n",
      " 1   label   4231 non-null   int64 \n",
      " 2   judul   4231 non-null   object\n",
      " 3   narasi  4231 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 132.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BG3FM7U8YWwG",
    "outputId": "77f028b7-6516-40aa-c5db-64258b27d491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3465\n",
       "0     766\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8n1OwapYWwR",
    "outputId": "984b159a-3343-4499-bf16-60e76f40debb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  label                                              judul  \\\n",
       "0   71      1  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  461      1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2  495      1  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3  550      1  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4  681      1       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "\n",
       "                                              narasi  \\\n",
       "0  A caller to a radio talk show recently shared ...   \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...   \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...   \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...   \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .   \n",
       "\n",
       "                                               total  \n",
       "0  Pemakaian Masker Menyebabkan Penyakit Legionna...  \n",
       "1  Instruksi Gubernur Jateng tentang penilangan  ...  \n",
       "2  Foto Jim Rohn: Jokowi adalah presiden terbaik ...  \n",
       "3  ini bukan politik, tapi kenyataan Pak Jokowi b...  \n",
       "4  Foto Kadrun kalo lihat foto ini panas dingin K...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total']=df['judul'] + ' ' + df['narasi']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qId8Pf4yYWwe",
    "outputId": "fef8fa24-a058-4ad4-b336-d98a580666c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>nama file gambar</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238057</td>\n",
       "      <td>2020-07-13 00:00:00</td>\n",
       "      <td>Narasi Tito Karnavian Berideologi Komunis Kare...</td>\n",
       "      <td>TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...</td>\n",
       "      <td>238057.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238158</td>\n",
       "      <td>2020-07-06 00:00:00</td>\n",
       "      <td>Anies: Seberat beratnya Pekerjaan Akan terasa ...</td>\n",
       "      <td>Seberat beratnya Pekerjaan Akan terasa ringan ...</td>\n",
       "      <td>238158.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238865</td>\n",
       "      <td>2020-04-22 00:00:00</td>\n",
       "      <td>Hindu di india Melemparkan Patung Buatan Merek...</td>\n",
       "      <td>Hindu di india melemparkan patung buatan merek...</td>\n",
       "      <td>238865.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248298</td>\n",
       "      <td>2019-10-22 00:00:00</td>\n",
       "      <td>RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...</td>\n",
       "      <td>Mulai Hari ini di RSCM mulai diPraktekkan Peny...</td>\n",
       "      <td>248298.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255176</td>\n",
       "      <td>2020-05-01 00:00:00</td>\n",
       "      <td>Permohonan Kelonggaran Angsuran ke OJK</td>\n",
       "      <td>Untuk sekedar info, Bagi anda yg punya ansuran...</td>\n",
       "      <td>255176.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID              tanggal  \\\n",
       "0  238057  2020-07-13 00:00:00   \n",
       "1  238158  2020-07-06 00:00:00   \n",
       "2  238865  2020-04-22 00:00:00   \n",
       "3  248298  2019-10-22 00:00:00   \n",
       "4  255176  2020-05-01 00:00:00   \n",
       "\n",
       "                                               judul  \\\n",
       "0  Narasi Tito Karnavian Berideologi Komunis Kare...   \n",
       "1  Anies: Seberat beratnya Pekerjaan Akan terasa ...   \n",
       "2  Hindu di india Melemparkan Patung Buatan Merek...   \n",
       "3  RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...   \n",
       "4             Permohonan Kelonggaran Angsuran ke OJK   \n",
       "\n",
       "                                              narasi nama file gambar  label  \n",
       "0  TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...       238057.jpg      1  \n",
       "1  Seberat beratnya Pekerjaan Akan terasa ringan ...       238158.jpg      1  \n",
       "2  Hindu di india melemparkan patung buatan merek...       238865.jpg      1  \n",
       "3  Mulai Hari ini di RSCM mulai diPraktekkan Peny...       248298.jpg      1  \n",
       "4  Untuk sekedar info, Bagi anda yg punya ansuran...       255176.jpg      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.read_excel('D:\\zzKoding\\Data Sains - Machine Learning - AI\\Lomba\\Satria Data 2020\\Data\\Data Uji BDC.xlsx')\n",
    "df_t_judul = df_t['judul']\n",
    "df_t_narasi = df_t['narasi']\n",
    "df_t_label = df_t['label']\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tvfJT52YWwo",
    "outputId": "82592c39-a7dd-4755-85ff-c5321237d8d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>label</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238057</td>\n",
       "      <td>Narasi Tito Karnavian Berideologi Komunis Kare...</td>\n",
       "      <td>TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...</td>\n",
       "      <td>1</td>\n",
       "      <td>Narasi Tito Karnavian Berideologi Komunis Kare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238158</td>\n",
       "      <td>Anies: Seberat beratnya Pekerjaan Akan terasa ...</td>\n",
       "      <td>Seberat beratnya Pekerjaan Akan terasa ringan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Anies: Seberat beratnya Pekerjaan Akan terasa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238865</td>\n",
       "      <td>Hindu di india Melemparkan Patung Buatan Merek...</td>\n",
       "      <td>Hindu di india melemparkan patung buatan merek...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hindu di india Melemparkan Patung Buatan Merek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248298</td>\n",
       "      <td>RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...</td>\n",
       "      <td>Mulai Hari ini di RSCM mulai diPraktekkan Peny...</td>\n",
       "      <td>1</td>\n",
       "      <td>RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255176</td>\n",
       "      <td>Permohonan Kelonggaran Angsuran ke OJK</td>\n",
       "      <td>Untuk sekedar info, Bagi anda yg punya ansuran...</td>\n",
       "      <td>1</td>\n",
       "      <td>Permohonan Kelonggaran Angsuran ke OJK Untuk s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                              judul  \\\n",
       "0  238057  Narasi Tito Karnavian Berideologi Komunis Kare...   \n",
       "1  238158  Anies: Seberat beratnya Pekerjaan Akan terasa ...   \n",
       "2  238865  Hindu di india Melemparkan Patung Buatan Merek...   \n",
       "3  248298  RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...   \n",
       "4  255176             Permohonan Kelonggaran Angsuran ke OJK   \n",
       "\n",
       "                                              narasi  label  \\\n",
       "0  TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...      1   \n",
       "1  Seberat beratnya Pekerjaan Akan terasa ringan ...      1   \n",
       "2  Hindu di india melemparkan patung buatan merek...      1   \n",
       "3  Mulai Hari ini di RSCM mulai diPraktekkan Peny...      1   \n",
       "4  Untuk sekedar info, Bagi anda yg punya ansuran...      1   \n",
       "\n",
       "                                               total  \n",
       "0  Narasi Tito Karnavian Berideologi Komunis Kare...  \n",
       "1  Anies: Seberat beratnya Pekerjaan Akan terasa ...  \n",
       "2  Hindu di india Melemparkan Patung Buatan Merek...  \n",
       "3  RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...  \n",
       "4  Permohonan Kelonggaran Angsuran ke OJK Untuk s...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t['total']=df_t['judul'] + ' ' + df_t['narasi']\n",
    "df_t = df_t.drop(['tanggal', 'nama file gambar'], axis=1)\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RMy-jS6dtJP"
   },
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MupeymT5YWwx",
    "outputId": "dbd57820-cb90-4ae3-c26f-eec2dc29bcf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jgxwi8PTd4AD"
   },
   "source": [
    "1. Stopwords Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P46lc3zaYWw3"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# ----------------------- get stopword from NLTK stopword -------------------------------\n",
    "# get stopword indonesia\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "stop_words = list_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVUk4oN0d9Pw"
   },
   "source": [
    "2. preprocessing data training dan testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvwOEHPUYWxF"
   },
   "outputs": [],
   "source": [
    "#preprocessing data training\n",
    "for index, row in df.iterrows():\n",
    "    filter_sentence = ''\n",
    "    sentence = row['total']\n",
    "    # Cleaning dengan regular expression\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Menghilangkan stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # Lower case\n",
    "    for words in words:\n",
    "        filter_sentence = filter_sentence  + ' ' + words.lower()\n",
    "    \n",
    "    df.loc[index, 'total'] = filter_sentence\n",
    "\n",
    "#preprocessing data testing    \n",
    "for index, row in df_t.iterrows():\n",
    "    filter_sentence = ''\n",
    "    sentence = row['total']\n",
    "    # Cleaning dengan regular expression\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Menghilangkan stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # Lower case\n",
    "    for words in words:\n",
    "        filter_sentence = filter_sentence  + ' ' + words.lower()\n",
    "    \n",
    "    df_t.loc[index, 'total'] = filter_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVOnGSROeF0e"
   },
   "source": [
    "3. Hasil Preprocessing Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYidiEb1YWxL",
    "outputId": "a485a0f1-9c13-418f-fba0-8c2b89044686"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "      <td>pemakaian masker menyebabkan penyakit legionn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "      <td>instruksi gubernur jateng penilangan yg berma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "      <td>foto jim rohn jokowi presiden terbaik dlm sej...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "      <td>politik kenyataan pak jokowi berhasil memulan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "      <td>foto kadrun kalo lihat foto panas dingin kadr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>event promo smartphone JNE 2020 spesial di bul...</td>\n",
       "      <td>selamat siang teman teman fb ku semuanyaü§©,cuma...</td>\n",
       "      <td>event promo smartphone jne 2020 spesial juni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1161</td>\n",
       "      <td>1</td>\n",
       "      <td>MEREKA SUDAH MEMPERSIAPKAN DIRI DENGAN BAIK UN...</td>\n",
       "      <td>LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...</td>\n",
       "      <td>mereka sudah mempersiapkan diri dengan baik u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1597</td>\n",
       "      <td>1</td>\n",
       "      <td>Foto Presiden Italia menangis karena tak cukup...</td>\n",
       "      <td>Italia punya fasilitas perawatan kesehatan ter...</td>\n",
       "      <td>foto presiden italia menangis lahan mengubur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2098</td>\n",
       "      <td>1</td>\n",
       "      <td>Kapolres Timor Tengah Utara , Nusa Tenggara Ti...</td>\n",
       "      <td>Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...</td>\n",
       "      <td>kapolres timor tengah utara nusa tenggara tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2226</td>\n",
       "      <td>1</td>\n",
       "      <td>Video Polisi china telah menganiaya wanita uig...</td>\n",
       "      <td>Polisi china telah menganiaya wanita uighur le...</td>\n",
       "      <td>video polisi china menganiaya wanita uighur l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  label                                              judul  \\\n",
       "0    71      1  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1   461      1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2   495      1  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3   550      1  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4   681      1       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "5   736      1  event promo smartphone JNE 2020 spesial di bul...   \n",
       "6  1161      1  MEREKA SUDAH MEMPERSIAPKAN DIRI DENGAN BAIK UN...   \n",
       "7  1597      1  Foto Presiden Italia menangis karena tak cukup...   \n",
       "8  2098      1  Kapolres Timor Tengah Utara , Nusa Tenggara Ti...   \n",
       "9  2226      1  Video Polisi china telah menganiaya wanita uig...   \n",
       "\n",
       "                                              narasi  \\\n",
       "0  A caller to a radio talk show recently shared ...   \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...   \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...   \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...   \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .   \n",
       "5  selamat siang teman teman fb ku semuanyaü§©,cuma...   \n",
       "6  LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...   \n",
       "7  Italia punya fasilitas perawatan kesehatan ter...   \n",
       "8  Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...   \n",
       "9  Polisi china telah menganiaya wanita uighur le...   \n",
       "\n",
       "                                               total  \n",
       "0   pemakaian masker menyebabkan penyakit legionn...  \n",
       "1   instruksi gubernur jateng penilangan yg berma...  \n",
       "2   foto jim rohn jokowi presiden terbaik dlm sej...  \n",
       "3   politik kenyataan pak jokowi berhasil memulan...  \n",
       "4   foto kadrun kalo lihat foto panas dingin kadr...  \n",
       "5   event promo smartphone jne 2020 spesial juni ...  \n",
       "6   mereka sudah mempersiapkan diri dengan baik u...  \n",
       "7   foto presiden italia menangis lahan mengubur ...  \n",
       "8   kapolres timor tengah utara nusa tenggara tim...  \n",
       "9   video polisi china menganiaya wanita uighur l...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCRV_lBuYWxT"
   },
   "outputs": [],
   "source": [
    "#inisiasi x dan y\n",
    "x_train = df['total']\n",
    "y_train = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L336jmTpeLma"
   },
   "source": [
    "4. Hasil Preprocessing Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DK3xeTh9YWxd",
    "outputId": "7ec83fb5-9ea0-45b8-8d45-119132785640"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>label</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238057</td>\n",
       "      <td>Narasi Tito Karnavian Berideologi Komunis Kare...</td>\n",
       "      <td>TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...</td>\n",
       "      <td>1</td>\n",
       "      <td>narasi tito karnavian berideologi komunis kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238158</td>\n",
       "      <td>Anies: Seberat beratnya Pekerjaan Akan terasa ...</td>\n",
       "      <td>Seberat beratnya Pekerjaan Akan terasa ringan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>anies seberat beratnya pekerjaan akan ringan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238865</td>\n",
       "      <td>Hindu di india Melemparkan Patung Buatan Merek...</td>\n",
       "      <td>Hindu di india melemparkan patung buatan merek...</td>\n",
       "      <td>1</td>\n",
       "      <td>hindu india melemparkan patung buatan mereka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248298</td>\n",
       "      <td>RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...</td>\n",
       "      <td>Mulai Hari ini di RSCM mulai diPraktekkan Peny...</td>\n",
       "      <td>1</td>\n",
       "      <td>rscm praktekkan penyedotan plug venasaluran d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255176</td>\n",
       "      <td>Permohonan Kelonggaran Angsuran ke OJK</td>\n",
       "      <td>Untuk sekedar info, Bagi anda yg punya ansuran...</td>\n",
       "      <td>1</td>\n",
       "      <td>permohonan kelonggaran angsuran ojk untuk sek...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                              judul  \\\n",
       "0  238057  Narasi Tito Karnavian Berideologi Komunis Kare...   \n",
       "1  238158  Anies: Seberat beratnya Pekerjaan Akan terasa ...   \n",
       "2  238865  Hindu di india Melemparkan Patung Buatan Merek...   \n",
       "3  248298  RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...   \n",
       "4  255176             Permohonan Kelonggaran Angsuran ke OJK   \n",
       "\n",
       "                                              narasi  label  \\\n",
       "0  TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...      1   \n",
       "1  Seberat beratnya Pekerjaan Akan terasa ringan ...      1   \n",
       "2  Hindu di india melemparkan patung buatan merek...      1   \n",
       "3  Mulai Hari ini di RSCM mulai diPraktekkan Peny...      1   \n",
       "4  Untuk sekedar info, Bagi anda yg punya ansuran...      1   \n",
       "\n",
       "                                               total  \n",
       "0   narasi tito karnavian berideologi komunis kar...  \n",
       "1   anies seberat beratnya pekerjaan akan ringan ...  \n",
       "2   hindu india melemparkan patung buatan mereka ...  \n",
       "3   rscm praktekkan penyedotan plug venasaluran d...  \n",
       "4   permohonan kelonggaran angsuran ojk untuk sek...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vga5FAMpYWxp"
   },
   "outputs": [],
   "source": [
    "x_test = df_t['total']\n",
    "y_test = df_t['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWNbraY9eSfq"
   },
   "source": [
    "# **Vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lakbMAMweW_7"
   },
   "source": [
    "1. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llx3Kw7NYWxy"
   },
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(max_df=1.0)\n",
    "\n",
    "#Fit and transform train set, transform test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Exz2IEc9etTJ"
   },
   "source": [
    "Membuat DataFrame berisi nilai TF IDF Data Training dan Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTKXu2kBYWx4",
    "outputId": "d52b73b7-f8dd-472c-fdad-3657b648ca00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21182</th>\n",
       "      <th>21183</th>\n",
       "      <th>21184</th>\n",
       "      <th>21185</th>\n",
       "      <th>21186</th>\n",
       "      <th>21187</th>\n",
       "      <th>21188</th>\n",
       "      <th>21189</th>\n",
       "      <th>21190</th>\n",
       "      <th>21191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   21182  21183  21184  21185  21186  21187  21188  21189  21190  21191  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 21192 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21182</th>\n",
       "      <th>21183</th>\n",
       "      <th>21184</th>\n",
       "      <th>21185</th>\n",
       "      <th>21186</th>\n",
       "      <th>21187</th>\n",
       "      <th>21188</th>\n",
       "      <th>21189</th>\n",
       "      <th>21190</th>\n",
       "      <th>21191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   21182  21183  21184  21185  21186  21187  21188  21189  21190  21191  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 21192 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_train_array = tfidf_train.toarray()\n",
    "tfidf_test_array = tfidf_test.toarray()\n",
    "tfidf_train_df = pd.DataFrame(tfidf_train_array)\n",
    "tfidf_test_df = pd.DataFrame(tfidf_test_array)\n",
    "display(tfidf_train_df.head())\n",
    "display(tfidf_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGigxVpZe6O8"
   },
   "source": [
    "2. Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMdwrQjvYWx-"
   },
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "#Fit and transform train set, transform test set\n",
    "count_train = count_vectorizer.fit_transform(x_train)\n",
    "count_test = count_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQYKw_qcYWyN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # print(tfidf_train[:1])\n",
    "# print(tfidf_test[:2])\n",
    "# print(x_test[:1])\n",
    "# print(y_train[:2])\n",
    "# # print(count_train[:1])\n",
    "# print(count_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJdAIEzIfB8U"
   },
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ngnj06HvfpYV"
   },
   "source": [
    "1. Passive - Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEZqjfK6f6gI"
   },
   "source": [
    "a. PAC TF  IDF Biasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hanM8azdYWyX",
    "outputId": "93fa2c4c-a47a-4341-e048-5422066502b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 90.77%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# PASSIVE-AGGRESSIVE CLASSIFIER TF-IDF   \n",
    "\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "#Predict on the test set\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "\n",
    "#F1 Score\n",
    "scoref1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {round(scoref1*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1cfz2xwgBeW"
   },
   "source": [
    "b. PAC TF-IDF Pakai DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQ6SjpWUYWyc",
    "outputId": "07ce977a-9390-45c7-f8b2-22123bb66515"
   },
   "outputs": [],
   "source": [
    "#PAC PAKE DF\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# PASSIVE-AGGRESSIVE CLASSIFIER TF-IDF   \n",
    "\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train_df,y_train)\n",
    "#Predict on the test set\n",
    "y_pred = pac.predict(tfidf_test_df)\n",
    "\n",
    "#F1 Score\n",
    "scoref1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {round(scoref1*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lscXi3v-gJVF"
   },
   "source": [
    "c. PAC Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WX6jfQ2TYWy1",
    "outputId": "ffdc01f2-4952-4cf4-ad64-761778a6d182"
   },
   "outputs": [],
   "source": [
    "# PASSIVE-AGGRESSIVE CLASSIFIER Count\n",
    "\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(count_train,y_train)\n",
    "\n",
    "#Predict on the test set\n",
    "y_pred=pac.predict(count_test)\n",
    "\n",
    "scoref1c=f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {round(scoref1c*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rKYW-ImgRCX"
   },
   "source": [
    "2. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jMF8zAD2gVRf"
   },
   "source": [
    "a. Multinomial NB biasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gL87NHy4YWy6",
    "outputId": "273d50d1-7deb-4b7a-e872-f5aa8f28e15b"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "#Multinomial NB TF-IDF\n",
    "\n",
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha, tfidf_train, y_train, tfidf_test, y_test):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.f1_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha, tfidf_train, y_train, tfidf_test, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4n_ZHzxgblR"
   },
   "source": [
    "b. Multinomial NB TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89vrbUgBYWzA",
    "outputId": "b3ee85d8-fc2f-470c-dbf8-b415baf0b5bf"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "#Multinomial NB TF-IDF\n",
    "\n",
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha, tfidf_train_df, y_train, tfidf_test_df, y_test):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train_df, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test_df)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.f1_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha, tfidf_train_df, y_train, tfidf_test_df, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0qrw_JjgjMv"
   },
   "source": [
    "3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emyHhrTRYWzO",
    "outputId": "ff1d7d81-b908-4543-83a7-4bc763f50db7"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(tfidf_train, y_train)\n",
    "Accuracy = logreg.score(tfidf_test, y_test)\n",
    "\n",
    "print(Accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEvDSOYMgqYj"
   },
   "source": [
    "# **Modelling Baru**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZvbUUXgIYWzY",
    "outputId": "186a8aeb-bf8e-4b0d-edec-35aebed221f1"
   },
   "outputs": [],
   "source": [
    "print(df_judul.head(3))\n",
    "print(df_narasi.head(3))\n",
    "print(df_t_judul.head(3))\n",
    "print(df_t_narasi.head(3))\n",
    "print(df_judul[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JR9dtuETg-qb"
   },
   "source": [
    "1. Preprocessing Data Training Baru\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7HHPLdPYWzd"
   },
   "outputs": [],
   "source": [
    "angka = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "tanda = ['?', '!', '.', ',', ' ']\n",
    "\n",
    "#buat dataframe kosong\n",
    "df_baru_train = pd.DataFrame()\n",
    "\n",
    "#preprocessing\n",
    "for index, row in df_judul.iteritems():\n",
    "    #check apakah di awal angka atau bukan\n",
    "    if row[0] in angka:\n",
    "        df_baru_train.loc[index, 'awal_angka'] = 1\n",
    "    elif row[0] not in angka:\n",
    "        df_baru_train.loc[index, 'awal_angka'] = 0\n",
    "\n",
    "    #check jumlah tanda baca\n",
    "    temp = 0\n",
    "    for x in row:\n",
    "        if x in tanda:\n",
    "            temp += 1\n",
    "    jumlah_tanda = temp\n",
    "    df_baru_train.loc[index, 'jumlah_tanda'] = jumlah_tanda\n",
    "    \n",
    "    #menghilangkan tanda baca\n",
    "    sentence = row\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    #tokenize\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    #hitung jumlah huruf\n",
    "    jumlah_huruf = len(words)\n",
    "    df_baru_train.loc[index, 'jumlah_huruf'] = jumlah_huruf\n",
    "    if (jumlah_tanda - jumlah_huruf) >= 0:\n",
    "        df_baru_train.loc[index, 'jumlah_tanda_tak_wajar'] = (jumlah_tanda - jumlah_huruf)\n",
    "    elif (jumlah_tanda - jumlah_huruf) < 0:\n",
    "        df_baru_train.loc[index, 'jumlah_tanda_tak_wajar'] = 0\n",
    "    \n",
    "    #stop words\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    temp2, temp3 = 0, 0\n",
    "    for w in words:\n",
    "        temp3 += 1\n",
    "        #jika huruf kapital\n",
    "        if w.isupper() == True: \n",
    "            temp2 += 1\n",
    "    if temp2 == temp3:\n",
    "        df_baru_train.loc[index, 'kalimat_kapital'] = 1\n",
    "    elif temp2 != temp3:\n",
    "        df_baru_train.loc[index, 'kalimat_kapital'] = 0\n",
    "        \n",
    "    kata_judul = row\n",
    "    kata_narasi = df_narasi[index]\n",
    "    kata_judul = re.sub(r'[^\\w\\s]', '', kata_judul)\n",
    "    kata_narasi = re.sub(r'[^\\w\\s]', '', kata_narasi)\n",
    "    # Tokenization\n",
    "    kata_judul = nltk.word_tokenize(kata_judul)\n",
    "    kata_narasi = nltk.word_tokenize(kata_narasi)\n",
    "    # Menghilangkan stopwords\n",
    "    kata_judul = [w.lower() for w in kata_judul if not w in stop_words]\n",
    "    kata_narasi = [w.lower() for w in kata_narasi if not w in stop_words]\n",
    "    temp4, temp5 = 0, 0\n",
    "    for w in kata_narasi:\n",
    "        temp4 += 1\n",
    "        if w in kata_judul:\n",
    "            temp5 += 1\n",
    "    df_baru_train.loc[index, 'jumlah_keyword'] = temp5\n",
    "    df_baru_train.loc[index, 'persentase_keyword'] = (temp5/temp4)*100\n",
    "    \n",
    "    df_baru_train.loc[index, 'label'] = df_label[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UtGJkOzCrJak"
   },
   "source": [
    "2. Data Training Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRQl0LMqYWzr",
    "outputId": "4403e4cf-d433-40a8-9862-e848892000d9"
   },
   "outputs": [],
   "source": [
    "df_baru_train['label'] = df_baru_train['label'].astype(int)\n",
    "# display(df_baru_train[df_baru_train['awal_angka']==1])\n",
    "display(len(df_baru_train[df_baru_train['jumlah_tanda']>df_baru_train['jumlah_huruf']]))\n",
    "display(len(df_baru_train[df_baru_train['kalimat_kapital'] == 1]))\n",
    "display(df_baru_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkpOIdIUYWzy"
   },
   "outputs": [],
   "source": [
    "hoax = df_baru_train[df_baru_train['label'] == 1]\n",
    "non_hoax = df_baru_train[df_baru_train['label'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFeKKkNRrZB6"
   },
   "source": [
    "3. Visualisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kehOQ3YYWz7"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Us9AppqmYWz_",
    "outputId": "360f8005-b905-4e97-f13d-f92f638f9a05"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15, 5.5))\n",
    "ax[0].set_title('Hoax persentase keyboard')\n",
    "sns.distplot(hoax['persentase_keyword'], ax=ax[0])\n",
    "\n",
    "ax[1].set_title('Non hoax persentase keyboard')\n",
    "sns.distplot(non_hoax['persentase_keyword'], ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmLCg_HPYW0M",
    "outputId": "d96fa83a-3bc4-43d3-d6d8-deb0ae5b3196"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15, 5.5))\n",
    "ax[0].set_title('Hoax tanda tak wajar')\n",
    "sns.countplot(x=hoax['jumlah_tanda_tak_wajar'], data=hoax, ax=ax[0])\n",
    "\n",
    "ax[1].set_title('Non hoax tanda tak wajar')\n",
    "sns.countplot(x=non_hoax['jumlah_tanda_tak_wajar'], data=non_hoax, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwGlRyQgYW0R",
    "outputId": "049aab35-df94-418b-b47e-8808e54d6d8f"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15, 5.5))\n",
    "ax[0].set_title('Hoax jumlah keyword')\n",
    "sns.countplot(x=hoax['jumlah_keyword'], data=hoax, ax=ax[0])\n",
    "\n",
    "ax[1].set_title('Non hoax jumlah keyword')\n",
    "sns.countplot(x=non_hoax['jumlah_keyword'], data=non_hoax, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocfKtkurYW0Z",
    "outputId": "d1bce860-fdad-47af-bf80-0f108f430f21"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15, 5.5))\n",
    "ax[0].set_title('Hoax kalimat_kapital')\n",
    "sns.countplot(x=hoax['kalimat_kapital'], data=hoax, ax=ax[0])\n",
    "\n",
    "ax[1].set_title('Non hoax kalimat_kapital')\n",
    "sns.countplot(x=non_hoax['kalimat_kapital'], data=non_hoax, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbH3zFc_YW0d",
    "outputId": "cd39e992-b01d-4dcb-e4e8-7fa18cdeba67"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15, 5.5))\n",
    "ax[0].set_title('Hoax awal_angka')\n",
    "sns.countplot(x=hoax['awal_angka'], data=hoax, ax=ax[0])\n",
    "\n",
    "ax[1].set_title('Non hoax awal_angka')\n",
    "sns.countplot(x=non_hoax['awal_angka'], data=non_hoax, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13iitgWhrf3r"
   },
   "source": [
    "3. Data Preprocessing (Data Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXsTvwkWYW0k"
   },
   "outputs": [],
   "source": [
    "angka = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "tanda = ['?', '!', '.', ',', ' ']\n",
    "df_baru_test = pd.DataFrame()\n",
    "for index, row in df_t_judul.iteritems():\n",
    "    if row[0] in angka:\n",
    "        df_baru_test.loc[index, 'awal_angka'] = 1\n",
    "    elif row[0] not in angka:\n",
    "        df_baru_test.loc[index, 'awal_angka'] = 0\n",
    "    temp = 0\n",
    "    for x in row:\n",
    "        if x in tanda:\n",
    "            temp += 1\n",
    "    jumlah_tanda = temp\n",
    "    df_baru_test.loc[index, 'jumlah_tanda'] = jumlah_tanda\n",
    "    \n",
    "    sentence = row\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    jumlah_huruf = len(words)\n",
    "    df_baru_test.loc[index, 'jumlah_huruf'] = jumlah_huruf\n",
    "    if (jumlah_tanda - jumlah_huruf) >= 0:\n",
    "        df_baru_test.loc[index, 'jumlah_tanda_tak_wajar'] = (jumlah_tanda - jumlah_huruf)\n",
    "    elif (jumlah_tanda - jumlah_huruf) < 0:\n",
    "        df_baru_test.loc[index, 'jumlah_tanda_tak_wajar'] = 0\n",
    "    \n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    temp2, temp3 = 0, 0\n",
    "    for w in words:\n",
    "        temp3 += 1\n",
    "        if w.isupper() == True:\n",
    "            temp2 += 1\n",
    "    if temp2 == temp3:\n",
    "        df_baru_test.loc[index, 'kalimat_kapital'] = 1\n",
    "    elif temp2 != temp3:\n",
    "        df_baru_test.loc[index, 'kalimat_kapital'] = 0\n",
    "        \n",
    "    kata_judul = row\n",
    "    kata_narasi = df_t_narasi[index]\n",
    "    kata_judul = re.sub(r'[^\\w\\s]', '', kata_judul)\n",
    "    kata_narasi = re.sub(r'[^\\w\\s]', '', kata_narasi)\n",
    "    # Tokenization\n",
    "    kata_judul = nltk.word_tokenize(kata_judul)\n",
    "    kata_narasi = nltk.word_tokenize(kata_narasi)\n",
    "    # Menghilangkan stopwords\n",
    "    kata_judul = [w.lower() for w in kata_judul if not w in stop_words]\n",
    "    kata_narasi = [w.lower() for w in kata_narasi if not w in stop_words]\n",
    "    temp4, temp5 = 0, 0\n",
    "    for w in kata_narasi:\n",
    "        temp4 += 1\n",
    "        if w in kata_judul:\n",
    "            temp5 += 1\n",
    "    df_baru_test.loc[index, 'jumlah_keyword'] = temp5\n",
    "    df_baru_test.loc[index, 'persentase_keyword'] = (temp5/temp4)*100\n",
    "    \n",
    "    df_baru_test.loc[index, 'label'] = df_t_label[index]\n",
    "\n",
    "df_baru_test['label'] = df_baru_test['label'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BycbisTrr2d"
   },
   "source": [
    "4. Dataframe Baru (Data Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIoPzZiuYW0u",
    "outputId": "a5cc4608-9fde-46d1-ee31-67293d4186ef"
   },
   "outputs": [],
   "source": [
    "display(df_baru_train.head(2))\n",
    "display(df_baru_test.head(2))\n",
    "\n",
    "df_baru_train = df_baru_train.drop(['jumlah_tanda', 'jumlah_huruf', 'jumlah_keyword'], axis=1)\n",
    "df_baru_test = df_baru_test.drop(['jumlah_tanda', 'jumlah_huruf', 'jumlah_keyword'], axis=1)\n",
    "\n",
    "display(df_baru_train.head(2))\n",
    "display(df_baru_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mSaEkiGuM1T"
   },
   "source": [
    "5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLg2zO-HYW01"
   },
   "outputs": [],
   "source": [
    "train_feature = ['awal_angka', 'jumlah_tanda_tak_wajar', 'kalimat_kapital', 'persentase_keyword']\n",
    "\n",
    "x_train = df_baru_train[train_feature]\n",
    "y_train = df_baru_train['label']\n",
    "x_test = df_baru_test[train_feature]\n",
    "y_test = df_baru_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMOQ3EvbuUl2"
   },
   "source": [
    "a. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ojy0Q6qYW08",
    "outputId": "4e7b3825-511c-4a25-9c52-972da19f35bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SutbajizuZCG"
   },
   "source": [
    "b. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeCWgBKiYW1C",
    "outputId": "ade90d66-cf4f-47fe-f695-08bb6b1971d5"
   },
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha, tfidf_train, y_train, tfidf_test, y_test):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.f1_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha, x_train, y_train, x_test, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FmE48rRuq5Q"
   },
   "source": [
    "7. Modelling Dataframe TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4PBnlCRYW1N",
    "outputId": "e9ad0d15-8ea4-41f9-e324-49001a342df4"
   },
   "outputs": [],
   "source": [
    "display(tfidf_train_df.head(2))\n",
    "display(x_train.head(2))\n",
    "print('tfidf train:', len(tfidf_train_df))\n",
    "print('x train:', len(x_train))\n",
    "X_train = pd.concat([tfidf_train_df, x_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAWQ2cwgYW1c",
    "outputId": "1f013eec-4cf7-49e0-d2ae-a77de56d2b73"
   },
   "outputs": [],
   "source": [
    "display(X_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7dy9RmhEYW1j",
    "outputId": "4304a1aa-485b-44e1-f61a-f94d288dfa15"
   },
   "outputs": [],
   "source": [
    "display(tfidf_test_df.head(2))\n",
    "display(x_test.head(2))\n",
    "print('tfidf test:', len(tfidf_test_df))\n",
    "print('x test:', len(x_test))\n",
    "X_test = pd.concat([tfidf_test_df, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOEHOX1_YW1s",
    "outputId": "1644a941-08c4-4931-8ce9-b7e2e3f8a399"
   },
   "outputs": [],
   "source": [
    "display(X_train.head(2))\n",
    "display(X_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuxchQmJYW12",
    "outputId": "7ef600da-56bf-4d58-afe3-0333ada87aa5"
   },
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha, tfidf_train, y_train, tfidf_test, y_test):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.f1_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjVz61FYz6sM"
   },
   "source": [
    "Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiZM3uO0YW2B",
    "outputId": "ab8ae11b-cc0f-4deb-f07b-c7f251f3100c"
   },
   "outputs": [],
   "source": [
    "#RF untuk \n",
    "\n",
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JzsXF-2YW2I",
    "outputId": "6348cd5e-dc73-44b6-9fca-2a3dc6b838be"
   },
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model2.fit(tfidf_train_df, y_train)\n",
    "pred = model2.predict(tfidf_test_df)\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hX7tc6t7YW2c",
    "outputId": "7c825000-d7c3-43d3-fc37-f8e0533e3742"
   },
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model3.fit(tfidf_train, y_train)\n",
    "pred = model3.predict(tfidf_test)\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jzqrh2cYW2h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lomba satria data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
